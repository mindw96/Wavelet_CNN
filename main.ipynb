{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "batch_size  = 512\n",
    "random_seed = 888\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data_path = './dataset/'\n",
    "texture_dataset = datasets.ImageFolder(\n",
    "    data_path,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]))\n",
    "\n",
    "class_names = {num:[texture_dataset.classes] for num in range(len(texture_dataset.classes))}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_idx, val_idx = train_test_split(list(range(len(texture_dataset))), test_size=0.2, random_state=random_seed)\n",
    "datasets = {}\n",
    "datasets['train'] = Subset(texture_dataset, train_idx)\n",
    "datasets['valid'] = Subset(texture_dataset, val_idx)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size : 512,  tvt : 17 / 5\n"
     ]
    }
   ],
   "source": [
    "dataloaders, batch_num = {}, {}\n",
    "dataloaders['train'] = torch.utils.data.DataLoader(datasets['train'],\n",
    "                                                   batch_size=batch_size, shuffle=True,\n",
    "                                                   num_workers=20)\n",
    "dataloaders['valid'] = torch.utils.data.DataLoader(datasets['valid'],\n",
    "                                                   batch_size=batch_size, shuffle=False,\n",
    "                                                   num_workers=20)\n",
    "\n",
    "batch_num['train'], batch_num['valid'] = len(dataloaders['train']), len(dataloaders['valid'])\n",
    "print('batch_size : %d,  tvt : %d / %d' % (batch_size, batch_num['train'], batch_num['valid']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def WaveletTransformAxisY(batch_img):\n",
    "    odd_img  = batch_img[:,0::2]\n",
    "    even_img = batch_img[:,1::2]\n",
    "    L = (odd_img + even_img) / 2.0\n",
    "    H = torch.abs(odd_img - even_img)\n",
    "\n",
    "    return L, H"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def WaveletTransformAxisX(batch_img):\n",
    "    # transpose + fliplr\n",
    "    tmp_batch = torch.permute(batch_img, (0, 2, 1))\n",
    "    tmp_batch = torch.fliplr(tmp_batch)\n",
    "    _dst_L, _dst_H = WaveletTransformAxisY(tmp_batch)\n",
    "    # transpose + flipud\n",
    "    dst_L = torch.permute(_dst_L, [0, 2, 1])\n",
    "    dst_L = torch.flipud(dst_L)\n",
    "    dst_H = torch.permute(_dst_H, [0, 2, 1])\n",
    "    dst_H = torch.flipud(dst_H)\n",
    "\n",
    "    return dst_L, dst_H"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def Wavelet(batch_image):\n",
    "    r = batch_image[:,0]\n",
    "    g = batch_image[:,1]\n",
    "    b = batch_image[:,2]\n",
    "\n",
    "    # level 1 decomposition\n",
    "    wavelet_L, wavelet_H = WaveletTransformAxisY(r)\n",
    "    r_wavelet_LL, r_wavelet_LH = WaveletTransformAxisX(wavelet_L)\n",
    "    r_wavelet_HL, r_wavelet_HH = WaveletTransformAxisX(wavelet_H)\n",
    "\n",
    "    wavelet_L, wavelet_H = WaveletTransformAxisY(g)\n",
    "    g_wavelet_LL, g_wavelet_LH = WaveletTransformAxisX(wavelet_L)\n",
    "    g_wavelet_HL, g_wavelet_HH = WaveletTransformAxisX(wavelet_H)\n",
    "\n",
    "    wavelet_L, wavelet_H = WaveletTransformAxisY(b)\n",
    "    b_wavelet_LL, b_wavelet_LH = WaveletTransformAxisX(wavelet_L)\n",
    "    b_wavelet_HL, b_wavelet_HH = WaveletTransformAxisX(wavelet_H)\n",
    "\n",
    "    wavelet_data = [r_wavelet_LL, r_wavelet_LH, r_wavelet_HL, r_wavelet_HH,\n",
    "                    g_wavelet_LL, g_wavelet_LH, g_wavelet_HL, g_wavelet_HH,\n",
    "                    b_wavelet_LL, b_wavelet_LH, b_wavelet_HL, b_wavelet_HH]\n",
    "    transform_batch = torch.stack(wavelet_data, axis=1)\n",
    "\n",
    "    # level 2 decomposition\n",
    "    wavelet_L2, wavelet_H2 = WaveletTransformAxisY(r_wavelet_LL)\n",
    "    r_wavelet_LL2, r_wavelet_LH2 = WaveletTransformAxisX(wavelet_L2)\n",
    "    r_wavelet_HL2, r_wavelet_HH2 = WaveletTransformAxisX(wavelet_H2)\n",
    "\n",
    "    wavelet_L2, wavelet_H2 = WaveletTransformAxisY(g_wavelet_LL)\n",
    "    g_wavelet_LL2, g_wavelet_LH2 = WaveletTransformAxisX(wavelet_L2)\n",
    "    g_wavelet_HL2, g_wavelet_HH2 = WaveletTransformAxisX(wavelet_H2)\n",
    "\n",
    "    wavelet_L2, wavelet_H2 = WaveletTransformAxisY(b_wavelet_LL)\n",
    "    b_wavelet_LL2, b_wavelet_LH2 = WaveletTransformAxisX(wavelet_L2)\n",
    "    b_wavelet_HL2, b_wavelet_HH2 = WaveletTransformAxisX(wavelet_H2)\n",
    "\n",
    "\n",
    "    wavelet_data_l2 = [r_wavelet_LL2, r_wavelet_LH2, r_wavelet_HL2, r_wavelet_HH2,\n",
    "                       g_wavelet_LL2, g_wavelet_LH2, g_wavelet_HL2, g_wavelet_HH2,\n",
    "                       b_wavelet_LL2, b_wavelet_LH2, b_wavelet_HL2, b_wavelet_HH2]\n",
    "    transform_batch_l2 = torch.stack(wavelet_data_l2, dim=1)\n",
    "\n",
    "    # level 3 decomposition\n",
    "    wavelet_L3, wavelet_H3 = WaveletTransformAxisY(r_wavelet_LL2)\n",
    "    r_wavelet_LL3, r_wavelet_LH3 = WaveletTransformAxisX(wavelet_L3)\n",
    "    r_wavelet_HL3, r_wavelet_HH3 = WaveletTransformAxisX(wavelet_H3)\n",
    "\n",
    "    wavelet_L3, wavelet_H3 = WaveletTransformAxisY(g_wavelet_LL2)\n",
    "    g_wavelet_LL3, g_wavelet_LH3 = WaveletTransformAxisX(wavelet_L3)\n",
    "    g_wavelet_HL3, g_wavelet_HH3 = WaveletTransformAxisX(wavelet_H3)\n",
    "\n",
    "    wavelet_L3, wavelet_H3 = WaveletTransformAxisY(b_wavelet_LL2)\n",
    "    b_wavelet_LL3, b_wavelet_LH3 = WaveletTransformAxisX(wavelet_L3)\n",
    "    b_wavelet_HL3, b_wavelet_HH3 = WaveletTransformAxisX(wavelet_H3)\n",
    "\n",
    "    wavelet_data_l3 = [r_wavelet_LL3, r_wavelet_LH3, r_wavelet_HL3, r_wavelet_HH3,\n",
    "                       g_wavelet_LL3, g_wavelet_LH3, g_wavelet_HL3, g_wavelet_HH3,\n",
    "                       b_wavelet_LL3, b_wavelet_LH3, b_wavelet_HL3, b_wavelet_HH3]\n",
    "    transform_batch_l3 = torch.stack(wavelet_data_l3, dim=1)\n",
    "\n",
    "    # level 4 decomposition\n",
    "    wavelet_L4, wavelet_H4 = WaveletTransformAxisY(r_wavelet_LL3)\n",
    "    r_wavelet_LL4, r_wavelet_LH4 = WaveletTransformAxisX(wavelet_L4)\n",
    "    r_wavelet_HL4, r_wavelet_HH4 = WaveletTransformAxisX(wavelet_H4)\n",
    "\n",
    "    wavelet_L4, wavelet_H4 = WaveletTransformAxisY(g_wavelet_LL3)\n",
    "    g_wavelet_LL4, g_wavelet_LH4 = WaveletTransformAxisX(wavelet_L4)\n",
    "    g_wavelet_HL4, g_wavelet_HH4 = WaveletTransformAxisX(wavelet_H4)\n",
    "\n",
    "    wavelet_L4, wavelet_H4 = WaveletTransformAxisY(b_wavelet_LL3)\n",
    "    b_wavelet_LL4, b_wavelet_LH4 = WaveletTransformAxisX(wavelet_L4)\n",
    "    b_wavelet_HL4, b_wavelet_HH4 = WaveletTransformAxisX(wavelet_H4)\n",
    "\n",
    "\n",
    "    wavelet_data_l4 = [r_wavelet_LL4, r_wavelet_LH4, r_wavelet_HL4, r_wavelet_HH4,\n",
    "                       g_wavelet_LL4, g_wavelet_LH4, g_wavelet_HL4, g_wavelet_HH4,\n",
    "                       b_wavelet_LL4, b_wavelet_LH4, b_wavelet_HL4, b_wavelet_HH4]\n",
    "    transform_batch_l4 = torch.stack(wavelet_data_l4, dim=1)\n",
    "\n",
    "    return [transform_batch, transform_batch_l2, transform_batch_l3, transform_batch_l4]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class Wavelet_Model(torch.nn.Module):\n",
    "    def __init__(self, classes=10):\n",
    "        super(Wavelet_Model, self).__init__()\n",
    "        self.conv_1 = nn.Conv2d(12, 64, kernel_size=(3, 3), padding=1)\n",
    "        self.norm_1 = nn.BatchNorm2d(64)\n",
    "        self.relu_1 = nn.ReLU()\n",
    "\n",
    "        self.conv_1_2 = nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=1)\n",
    "        self.norm_1_2 = nn.BatchNorm2d(64)\n",
    "        self.relu_1_2 = nn.ReLU()\n",
    "        #################################################################################################\n",
    "        self.conv_a = nn.Conv2d(12, 64, kernel_size=(3, 3), padding=1)\n",
    "        self.norm_a = nn.BatchNorm2d(64)\n",
    "        self.relu_a = nn.ReLU()\n",
    "        #################################################################################################\n",
    "        self.conv_2 = nn.Conv2d(128, 128, kernel_size=(3, 3), padding=1)\n",
    "        self.norm_2 = nn.BatchNorm2d(128)\n",
    "        self.relu_2 = nn.ReLU()\n",
    "\n",
    "        self.conv_2_2 = nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=1)\n",
    "        self.norm_2_2 = nn.BatchNorm2d(128)\n",
    "        self.relu_2_2 = nn.ReLU()\n",
    "        #################################################################################################\n",
    "        self.conv_b = nn.Conv2d(12, 128, kernel_size=(3, 3), padding=1)\n",
    "        self.norm_b = nn.BatchNorm2d(128)\n",
    "        self.relu_b = nn.ReLU()\n",
    "\n",
    "        self.conv_b_2 = nn.Conv2d(128, 128, kernel_size=(3, 3), padding=1)\n",
    "        self.norm_b_2 = nn.BatchNorm2d(128)\n",
    "        self.relu_b_2 = nn.ReLU()\n",
    "        #################################################################################################\n",
    "        self.conv_3 = nn.Conv2d(256, 256, kernel_size=(3, 3), padding=1)\n",
    "        self.norm_3 = nn.BatchNorm2d(256)\n",
    "        self.relu_3 = nn.ReLU()\n",
    "\n",
    "        self.conv_3_2 = nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=1)\n",
    "        self.norm_3_2 = nn.BatchNorm2d(256)\n",
    "        self.relu_3_2 = nn.ReLU()\n",
    "        #################################################################################################\n",
    "        self.conv_c = nn.Conv2d(12, 256, kernel_size=(3, 3), padding=1)\n",
    "        self.norm_c = nn.BatchNorm2d(256)\n",
    "        self.relu_c = nn.ReLU()\n",
    "\n",
    "        self.conv_c_2 = nn.Conv2d(256, 256, kernel_size=(3, 3), padding=1)\n",
    "        self.norm_c_2 = nn.BatchNorm2d(256)\n",
    "        self.relu_c_2 = nn.ReLU()\n",
    "\n",
    "        self.conv_c_3 = nn.Conv2d(256, 256, kernel_size=(3, 3), padding=1)\n",
    "        self.norm_c_3 = nn.BatchNorm2d(256)\n",
    "        self.relu_c_3 = nn.ReLU()\n",
    "        #################################################################################################\n",
    "        self.conv_4 = nn.Conv2d(512, 256, kernel_size=(3, 3), padding=1)\n",
    "        self.norm_4 = nn.BatchNorm2d(256)\n",
    "        self.relu_4 = nn.ReLU()\n",
    "\n",
    "        self.conv_4_2 = nn.Conv2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=1)\n",
    "        self.norm_4_2 = nn.BatchNorm2d(128)\n",
    "        self.relu_4_2 = nn.ReLU()\n",
    "        #################################################################################################\n",
    "        self.conv_5 = nn.Conv2d(128, 128, kernel_size=(3, 3), padding=1)\n",
    "        self.norm_5 = nn.BatchNorm2d(128)\n",
    "        self.relu_5 = nn.ReLU()\n",
    "\n",
    "        self.pool_5 = nn.AvgPool2d(kernel_size=(7,7), stride=1, padding=1)\n",
    "        self.flat_5 = nn.Flatten()\n",
    "\n",
    "        self.fc_5 = nn.Linear(1152, 2048)\n",
    "        self.norm_5_1 = nn.BatchNorm1d(2048)\n",
    "        self.relu_5_1 = nn.ReLU()\n",
    "        self.drop_5 = nn.Dropout(0.5)\n",
    "        #################################################################################################\n",
    "        self.fc_6 = nn.Linear(2048, classes)\n",
    "        self.norm_6 = nn.BatchNorm1d(classes)\n",
    "        self.relu_6 = nn.ReLU()\n",
    "        self.drop_6 = nn.Dropout(0.5)\n",
    "        #################################################################################################\n",
    "        self.output_fc = nn.Linear(classes, classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_l1, input_l2, input_l3, input_l4 = Wavelet(x)\n",
    "        #################################################################################################\n",
    "        # print('input shape: ', input_l1.shape)\n",
    "        out_1 = self.conv_1(input_l1)\n",
    "        # print('conv_1 output shape: ', out_1.shape)\n",
    "        out_1 = self.norm_1(out_1)\n",
    "        out_1 = self.relu_1(out_1)\n",
    "\n",
    "        out_1 = self.conv_1_2(out_1)\n",
    "        # print('conv_1_2 output shape: ', out_1.shape)\n",
    "        out_1 = self.norm_1_2(out_1)\n",
    "        out_1 = self.relu_1_2(out_1)\n",
    "        #################################################################################################\n",
    "        out_2 = self.conv_a(input_l2)\n",
    "        # print('conv_a output shape: ', out_2.shape)\n",
    "        out_2 = self.norm_a(out_2)\n",
    "        out_2 = self.relu_a(out_2)\n",
    "\n",
    "        cat_2 = torch.cat((out_1, out_2), 1)\n",
    "        # print('concatenate result: ', cat_2.shape)\n",
    "        out_2 = self.conv_2(cat_2)\n",
    "        # print('conv_2 output shape: ', out_2.shape)\n",
    "        out_2 = self.norm_2(out_2)\n",
    "        out_2 = self.relu_2(out_2)\n",
    "\n",
    "        out_2 = self.conv_2_2(out_2)\n",
    "        # print('conv_2_2 output shape: ', out_2.shape)\n",
    "        out_2 = self.norm_2_2(out_2)\n",
    "        out_2 = self.relu_2_2(out_2)\n",
    "        #################################################################################################\n",
    "        out_3 = self.conv_b(input_l3)\n",
    "        # print('conv_b output shape: ', out_3.shape)\n",
    "        out_3 = self.norm_b(out_3)\n",
    "        out_3 = self.relu_b(out_3)\n",
    "\n",
    "        out_3 = self.conv_b_2(out_3)\n",
    "        # print('conv_b_2 output shape: ', out_3.shape)\n",
    "        out_3 = self.norm_b_2(out_3)\n",
    "        out_3 = self.relu_b_2(out_3)\n",
    "        #################################################################################################\n",
    "        cat_3 = torch.cat((out_2, out_3), 1)\n",
    "        # print('concatenate result: ', cat_3.shape)\n",
    "        out_3 = self.conv_3(cat_3)\n",
    "        # print('conv_3 output shape: ', out_3.shape)\n",
    "        out_3 = self.norm_3(out_3)\n",
    "        out_3 = self.relu_3(out_3)\n",
    "\n",
    "        out_3 = self.conv_3_2(out_3)\n",
    "        # print('conv_3_2 output shape: ', out_3.shape)\n",
    "        out_3 = self.norm_3_2(out_3)\n",
    "        out_3 = self.relu_3_2(out_3)\n",
    "        #################################################################################################\n",
    "        out_4 = self.conv_c(input_l4)\n",
    "        # print('conv_c output shape: ', out_4.shape)\n",
    "        out_4 = self.norm_c(out_4)\n",
    "        out_4 = self.relu_c(out_4)\n",
    "\n",
    "        out_4 = self.conv_c_2(out_4)\n",
    "        # print('conv_c_2 output shape: ', out_4.shape)\n",
    "        out_4 = self.norm_c_2(out_4)\n",
    "        out_4 = self.relu_c_2(out_4)\n",
    "\n",
    "        out_4 = self.conv_c_3(out_4)\n",
    "        # print('conv_c_3 output shape: ', out_4.shape)\n",
    "        out_4 = self.norm_c_3(out_4)\n",
    "        out_4 = self.relu_c_3(out_4)\n",
    "        #################################################################################################\n",
    "        cat_4 = torch.cat((out_3, out_4), 1)\n",
    "        # print('concatenate result: ', cat_4.shape)\n",
    "        out_4 = self.conv_4(cat_4)\n",
    "        # print('conv_4 output shape: ', out_4.shape)\n",
    "        out_4 = self.norm_4(out_4)\n",
    "        out_4 = self.relu_4(out_4)\n",
    "\n",
    "        out_4 = self.conv_4_2(out_4)\n",
    "        # print('conv_4_2 output shape: ', out_4.shape)\n",
    "        out_4 = self.norm_4_2(out_4)\n",
    "        out_4 = self.relu_4_2(out_4)\n",
    "        #################################################################################################\n",
    "        out_5 = self.conv_5(out_4)\n",
    "        # print('conv_5 output shape: ', out_5.shape)\n",
    "        out_5 = self.norm_5(out_5)\n",
    "        out_5 = self.relu_5(out_5)\n",
    "\n",
    "        out_5 = self.pool_5(out_5)\n",
    "        out_5 = self.flat_5(out_5)\n",
    "        #################################################################################################\n",
    "        out_5 = self.fc_5(out_5)\n",
    "        # print('fc_5 output shape: ', out_5.shape)\n",
    "        out_5 = self.norm_5_1(out_5)\n",
    "        out_5 = self.relu_5_1(out_5)\n",
    "        out_5 = self.drop_5(out_5)\n",
    "\n",
    "        out_6 = self.fc_6(out_5)\n",
    "        # print('fc6 output shape: ', out_6.shape)\n",
    "        out_6 = self.norm_6(out_6)\n",
    "        out_6 = self.relu_6(out_6)\n",
    "        out_6 = self.drop_6(out_6)\n",
    "        #################################################################################################\n",
    "        output = self.output_fc(out_6)\n",
    "\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "model = Wavelet_Model(classes=58).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "since = time.time()\n",
    "\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "train_loss, train_acc, valid_loss, valid_acc = [], [], [], []\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.0001, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "lmbda = lambda epoch: 0.98739\n",
    "exp_lr_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lmbda)\n",
    "num_epochs=1000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "    print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in ['train', 'valid']:\n",
    "        if phase == 'train':\n",
    "            model.train()  # Set model to training mode\n",
    "        else:\n",
    "            model.eval()   # Set model to evaluate mode\n",
    "\n",
    "        running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            num_cnt += len(labels)\n",
    "        if phase == 'train':\n",
    "            exp_lr_scheduler.step()\n",
    "\n",
    "        epoch_loss = float(running_loss / num_cnt)\n",
    "        epoch_acc  = float((running_corrects.double() / num_cnt).cpu()*100)\n",
    "\n",
    "        if phase == 'train':\n",
    "            train_loss.append(epoch_loss)\n",
    "            train_acc.append(epoch_acc)\n",
    "        else:\n",
    "            valid_loss.append(epoch_loss)\n",
    "            valid_acc.append(epoch_acc)\n",
    "        print('{} Loss: {:.2f} Acc: {:.1f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "        # deep copy the model\n",
    "        if phase == 'valid' and epoch_acc > best_acc:\n",
    "            best_idx = epoch\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            #                 best_model_wts = copy.deepcopy(model.module.state_dict())\n",
    "            print('==> best model saved - %d / %.1f'%(best_idx + 1, best_acc))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "print('Best valid Acc: %d - %.1f' %(best_idx, best_acc))\n",
    "\n",
    "# load best model weights\n",
    "model.load_state_dict(best_model_wts)\n",
    "torch.save(model.state_dict(), 'Wavelet_cnn.pt')\n",
    "print('model saved')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('best model : %d - %1.f / %.1f'%(best_idx, valid_acc[best_idx], valid_loss[best_idx]))\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.plot(train_acc, 'b-')\n",
    "ax1.plot(valid_acc, 'r-')\n",
    "plt.plot(best_idx, valid_acc[best_idx], 'ro')\n",
    "ax1.set_xlabel('epoch')\n",
    "# Make the y-axis label, ticks and tick labels match the line color.\n",
    "ax1.set_ylabel('acc', color='k')\n",
    "ax1.tick_params('y', colors='k')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(train_loss, 'g-')\n",
    "ax2.plot(valid_loss, 'k-')\n",
    "plt.plot(best_idx, valid_loss[best_idx], 'ro')\n",
    "ax2.set_ylabel('loss', color='k')\n",
    "ax2.tick_params('y', colors='k')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "outputs": [
    {
     "data": {
      "text/plain": "Wavelet_Model(\n  (conv_1): Conv2d(12, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu_1): ReLU()\n  (conv_1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n  (norm_1_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu_1_2): ReLU()\n  (conv_a): Conv2d(12, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (norm_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu_a): ReLU()\n  (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (norm_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu_2): ReLU()\n  (conv_2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n  (norm_2_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu_2_2): ReLU()\n  (conv_b): Conv2d(12, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (norm_b): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu_b): ReLU()\n  (conv_b_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (norm_b_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu_b_2): ReLU()\n  (conv_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (norm_3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu_3): ReLU()\n  (conv_3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n  (norm_3_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu_3_2): ReLU()\n  (conv_c): Conv2d(12, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (norm_c): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu_c): ReLU()\n  (conv_c_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (norm_c_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu_c_2): ReLU()\n  (conv_c_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (norm_c_3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu_c_3): ReLU()\n  (conv_4): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (norm_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu_4): ReLU()\n  (conv_4_2): Conv2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n  (norm_4_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu_4_2): ReLU()\n  (conv_5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (norm_5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu_5): ReLU()\n  (pool_5): AvgPool2d(kernel_size=(7, 7), stride=1, padding=1)\n  (flat_5): Flatten(start_dim=1, end_dim=-1)\n  (fc_5): Linear(in_features=1152, out_features=2048, bias=True)\n  (norm_5_1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu_5_1): ReLU()\n  (drop_5): Dropout(p=0.5, inplace=False)\n  (fc_6): Linear(in_features=2048, out_features=58, bias=True)\n  (norm_6): BatchNorm1d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu_6): ReLU()\n  (drop_6): Dropout(p=0.5, inplace=False)\n  (output_fc): Linear(in_features=58, out_features=58, bias=True)\n)"
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Wavelet_Model(classes=58)\n",
    "model.load_state_dict(torch.load('./Wavelet_cnn.pt'))\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "img = Image.open('./test_samples/cork.png')\n",
    "tf = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()])\n",
    "img_tensor = tf(img)\n",
    "img_tensor = img_tensor.unsqueeze(0)\n",
    "print(img_tensor.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to cotton with a 10.97 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "output = model(img_tensor)\n",
    "_, predict = torch.max(output, 1)\n",
    "score = torch.nn.functional.softmax(output, dim=1).detach().numpy()\n",
    "img.show()\n",
    "\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "        .format(class_names[(np.argmax(score))], 100 * np.max(score))\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = None\n",
    "inputs = None\n",
    "labels = None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "wavelet",
   "language": "python",
   "display_name": "wavelet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}